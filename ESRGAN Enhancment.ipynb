{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a892dae7-74aa-4e58-bbf9-78db1d19381e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import matplotlib.pyplot as plt\n",
    "os.environ[\"TFHUB_DOWNLOAD_PROGRESS\"] = \"True\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93798708-90f3-4d06-a14f-8061d43c4164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declaring Constants\n",
    "IMAGE_PATHS = [\"1.jpg\",\"2.jpg\",\"3.jpg\",\"4.jpg\",\"5.jpg\",\"6.jpg\",\"7.jpg\",\"8.jpg\",\"9.jpg\",\"101.jpg\",\"11.jpg\",\"12.jpg\",\"13.jpg\",\"14.jpg\",\"15.jpg\",\"16.jpg\",\"17.jpg\",\"18.jpg\"]  # Add more image paths as needed\n",
    "SAVED_MODEL_PATH = \"https://tfhub.dev/captain-pool/esrgan-tf2/1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe721d64-9e6e-444f-923e-5dcbfd912863",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_images(image_paths):\n",
    "    \"\"\" Loads images from paths and preprocesses them to make them model ready\n",
    "        Args:\n",
    "          image_paths: List of paths to the image files\n",
    "    \"\"\"\n",
    "    hr_images = []\n",
    "    for path in image_paths:\n",
    "        hr_image = tf.image.decode_image(tf.io.read_file(path))\n",
    "        # If PNG, remove the alpha channel. The model only supports\n",
    "        # images with 3 color channels.\n",
    "        if hr_image.shape[-1] == 4:\n",
    "            hr_image = hr_image[...,:-1]\n",
    "        hr_size = (tf.convert_to_tensor(hr_image.shape[:-1]) // 4) * 4\n",
    "        hr_image = tf.image.crop_to_bounding_box(hr_image, 0, 0, hr_size[0], hr_size[1])\n",
    "        hr_image = tf.cast(hr_image, tf.float32)\n",
    "        hr_images.append(tf.expand_dims(hr_image, 0))\n",
    "    return hr_images\n",
    "\n",
    "\n",
    "\n",
    "def save_image(image, filename):\n",
    "  \"\"\"\n",
    "    Saves unscaled Tensor Images.\n",
    "    Args:\n",
    "      image: 3D image tensor. [height, width, channels]\n",
    "      filename: Name of the file to save.\n",
    "  \"\"\"\n",
    "  if not isinstance(image, Image.Image):\n",
    "    image = tf.clip_by_value(image, 0, 255)\n",
    "    image = Image.fromarray(tf.cast(image, tf.uint8).numpy())\n",
    "  image.save(\"%s.jpg\" % filename)\n",
    "  print(\"Saved as %s.jpg\" % filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "faa525bf-990b-4c57-ba5d-9dfa4bcba2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "def plot_image(image, title=\"\"):\n",
    "  \"\"\"\n",
    "    Plots images from image tensors.\n",
    "    Args:\n",
    "      image: 3D image tensor. [height, width, channels].\n",
    "      title: Title to display in the plot.\n",
    "  \"\"\"\n",
    "  image = np.asarray(image)\n",
    "  image = tf.clip_by_value(image, 0, 255)\n",
    "  image = Image.fromarray(tf.cast(image, tf.uint8).numpy())\n",
    "  plt.imshow(image)\n",
    "  plt.axis(\"off\")\n",
    "  plt.title(title)\n",
    "\n",
    "def divide_images(images, num_parts):\n",
    "  \"\"\" Divides each image into equal square parts\n",
    "      Args:\n",
    "        images: List of input image tensors.\n",
    "        num_parts: Number of parts to divide each image into.\n",
    "      Returns:\n",
    "        A list of lists, where each inner list contains the divided image tensors for an image.\n",
    "  \"\"\"\n",
    "  divided_images = []\n",
    "  for image in images:\n",
    "    height, width, _ = image.shape\n",
    "    part_size = min(height, width) // num_parts\n",
    "    parts = []\n",
    "    for i in range(num_parts):\n",
    "      for j in range(num_parts):\n",
    "        part = image[i * part_size : (i + 1) * part_size, j * part_size : (j + 1) * part_size, :]\n",
    "        parts.append(part)\n",
    "    divided_images.append(parts)\n",
    "  return divided_images\n",
    "\n",
    "\n",
    "def combine_image(parts, num_parts):\n",
    "  \"\"\" Combines the divided image parts into a single image\n",
    "      Args:\n",
    "        parts: List of divided image tensors.\n",
    "        num_parts: Number of parts the image was divided into.\n",
    "      Returns:\n",
    "        The combined image tensor.\n",
    "  \"\"\"\n",
    "  part_size = parts[0].shape[0]\n",
    "  combined_image = np.zeros((part_size * num_parts, part_size * num_parts, 3))\n",
    "  for i in range(num_parts):\n",
    "    for j in range(num_parts):\n",
    "      part = parts[i * num_parts + j]\n",
    "      combined_image[i * part_size : (i + 1) * part_size, j * part_size : (j + 1) * part_size, :] = part\n",
    "  return combined_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bbcd7c39-5df0-498e-8ccf-e884c2c0f3e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved as Original_Image_1.jpg\n",
      "Saved as Super_Resolution_1.jpg\n",
      "Time Taken: 2.895662\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess the input images\n",
    "hr_images = preprocess_images(IMAGE_PATHS)\n",
    "\n",
    "# Divide the images into equal square parts\n",
    "num_parts = 4  # 4x4 parts\n",
    "divided_images = divide_images([tf.squeeze(hr_image) for hr_image in hr_images], num_parts)\n",
    "\n",
    "# Load the super-resolution model\n",
    "model = hub.load(SAVED_MODEL_PATH)\n",
    "\n",
    "# Process each image and its parts individually\n",
    "start = time.time()\n",
    "fake_images = []\n",
    "for i, parts in enumerate(divided_images):\n",
    "  fake_image_parts = []\n",
    "  for part in parts:\n",
    "    fake_image = model(tf.expand_dims(part, 0))\n",
    "    fake_image = tf.squeeze(fake_image)\n",
    "    fake_image_parts.append(fake_image)\n",
    "  combined_image = combine_image(fake_image_parts, num_parts)\n",
    "  fake_images.append(combined_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472a11e1-ffcb-4a5f-b182-340964750985",
   "metadata": {},
   "outputs": [],
   "source": [
    "  # Save the images\n",
    "  save_image(tf.squeeze(hr_images[i]), filename=f\"Original_Image_{i+1}\")\n",
    "  save_image(combined_image, filename=f\"Super_Resolution_{i+1}\")\n",
    "print(\"Time Taken: %f\" % (time.time() - start))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
